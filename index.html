<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link
			rel="stylesheet"
			href="//cdnjs.cloudflare.com/ajax/libs/milligram/1.3.0/milligram.css"
		/>
		<title>Speech Doodle</title>
	</head>
	<body>
		<h1>Speech Doodle</h1>
		<div class="canvas-container"></div>
		<canvas class="visualizer" width="500" height="60px"></canvas>

		<div id="controls">
			<button id="recordButton">Record</button>
			<button id="transcribeButton" disabled>Get transcription</button>
		</div>
		<div id="output"></div>

		<!-- RECORDER JS -->
		<script src="https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js"></script>

		<section class="sound-clips"></section>

		<article>
			<p></p>
		</article>

		<!--  -->
		<script>
			// set up basic variables for app
			let rec = null
			let audioStream = null
			const LOCALHOST_API_URL = 'http://localhost:3000/upload_sound'
			const API_URL = 'https://speech-doodle-api.herokuapp.com/upload_sound'

			const recordButton = document.getElementById('recordButton')
			const transcribeButton = document.getElementById('transcribeButton')
			recordButton.addEventListener('click', startRecording)
			transcribeButton.addEventListener('click', transcribeText)

			const soundClips = document.querySelector('.sound-clips')
			const canvas = document.querySelector('.visualizer')

			// RECORD
			function startRecording() {
				let constraints = { audio: true, video: false }

				recordButton.disabled = true
				transcribeButton.disabled = false

				navigator.mediaDevices
					.getUserMedia(constraints)
					.then(function(stream) {
						const audioContext = new window.AudioContext()
						audioStream = stream
						const input = audioContext.createMediaStreamSource(stream)
						rec = new Recorder(input, { numChannels: 1 })
						rec.record()
					})
					.catch(function(err) {
						recordButton.disabled = false
						transcribeButton.disabled = true
					})
			}

			// TRANSCRIBE
			function transcribeText() {
				transcribeButton.disabled = true
				recordButton.disabled = false
				rec.stop()
				audioStream.getAudioTracks()[0].stop()
				rec.exportWAV(uploadSoundData)
			}

			// UPLOAD SOUND
			function uploadSoundData(blob) {
				let filename = new Date().toISOString()

				// == PLAYER
				const clipContainer = document.querySelector('article')
				const audio = document.createElement('audio')
				const clipLabel = document.querySelector('article>p')
				audio.setAttribute('controls', '')
				clipLabel.textContent = 'fileName'
				clipContainer.appendChild(audio)
				//
				const audioURL = window.URL.createObjectURL(blob)
				audio.src = audioURL
				// =====

				let xhr = new XMLHttpRequest()
				xhr.onload = function(e) {
					if (this.readyState === 4) {
						document.getElementById(
							'output'
						).innerHTML = `<br><br><strong>Result: </strong>${e.target.responseText}`
					}
				}
				let formData = new FormData()
				formData.append('audio_data', blob, filename)
				xhr.open('POST', LOCALHOST_API_URL, true)
				xhr.send(formData)
			}

			// visualiser setup - create web audio api context and canvas
		</script>
	</body>
</html>
